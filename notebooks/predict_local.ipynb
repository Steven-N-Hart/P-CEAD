{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yd5gaL2lI0u_",
    "outputId": "529295e3-1529-4218-85e7-3c3248c0564b"
   },
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from proganomaly_modules.training_module.trainer import custom_layers\n",
    "\n",
    "from proganomaly_modules.inference_module import image_utils\n",
    "from proganomaly_modules.inference_module import gan_inference\n",
    "from proganomaly_modules.inference_module import inference_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UFKksNwuI0xE"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4AwQzK8I0xT"
   },
   "source": [
    "### Set batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-8gRoTkI0xT"
   },
   "outputs": [],
   "source": [
    "batch_size_Z = 8\n",
    "batch_size_query_images = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxch4X7NI0xV"
   },
   "source": [
    "### Get Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YkttjtMrI0xV"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "Z = tf.random.normal(shape=(batch_size_Z, 512), mean=0.0, stddev=1.0, dtype=tf.float32, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dg3CT5mCI0xY"
   },
   "source": [
    "### Get query images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"normal_skin\"\n",
    "dataset_name = \"bach_breast\"\n",
    "# dataset_name = \"mnist\"\n",
    "# dataset_name = \"cifar10_car\"\n",
    "# dataset_name = \"cifar10\"\n",
    "# dataset_name = \"celeba_hq\"\n",
    "if dataset_name == \"normal_skin\":\n",
    "    size = 1024\n",
    "    block_idx = int(math.log(size, 2)) - 2\n",
    "    dataset = inference_inputs.read_dataset(\n",
    "        file_pattern=\"gs://.../TF_DIR/{0}/{0}.svs.{1}.tfrecords\".format(\n",
    "            slide_name, 8 - block_idx\n",
    "        ),\n",
    "        batch_size=batch_size_query_images,\n",
    "        block_idx=block_idx,\n",
    "        params={\n",
    "            \"use_multiple_resolution_records\": True,\n",
    "            \"tf_record_example_schema\": [\n",
    "                {\n",
    "                    \"name\": \"image/encoded\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"str\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/name\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"str\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/width\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/height\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/rescale_factor\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/rescale_factor\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                }\n",
    "            ],\n",
    "            \"image_feature_name\": \"image/encoded\",\n",
    "            \"image_encoding\": \"png\",\n",
    "            \"image_predownscaled_height\": 1024,\n",
    "            \"image_predownscaled_width\": 1024,\n",
    "            \"image_depth\": 3,\n",
    "            \"label_feature_name\": \"\",\n",
    "            \"input_fn_autotune\": False,\n",
    "            \"generator_projection_dims\": [4, 4, 512]\n",
    "        }\n",
    "    )().take(1)\n",
    "\n",
    "    for batch in dataset:\n",
    "        numpy_batch = {k: v.numpy() for k, v in batch.items()}\n",
    "elif dataset_name == \"bach_breast\":\n",
    "    size = 512\n",
    "    block_idx = int(math.log(size, 2)) - 2\n",
    "    dataset = inference_inputs.read_dataset(\n",
    "        file_pattern=\"gs://.../BACH/train/{0}/{0}_L{1}.tfrecords\".format(\n",
    "            \"{slide_name}\", 8 - block_idx\n",
    "        ),\n",
    "        batch_size=batch_size_query_images,\n",
    "        block_idx=block_idx,\n",
    "        params={\n",
    "            \"use_multiple_resolution_records\": True,\n",
    "            \"tf_record_example_schema\": [\n",
    "                {\n",
    "                    \"name\": \"image/encoded\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"str\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/name\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"str\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/width\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"image/height\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                }\n",
    "            ],\n",
    "            \"image_feature_name\": \"image/encoded\",\n",
    "            \"image_encoding\": \"png\",\n",
    "            \"image_predownscaled_height\": 512,\n",
    "            \"image_predownscaled_width\": 512,\n",
    "            \"image_depth\": 3,\n",
    "            \"label_feature_name\": \"\",\n",
    "            \"input_fn_autotune\": False,\n",
    "            \"generator_projection_dims\": [4, 4, 512]\n",
    "        }\n",
    "    )().take(1)\n",
    "\n",
    "    for batch in dataset:\n",
    "        numpy_batch = {k: v.numpy() for k, v in batch.items()}\n",
    "elif dataset_name == \"mnist\":\n",
    "    size = 32\n",
    "    dataset = training_inputs.mnist_dataset(\n",
    "        batch_size=batch_size_query_images,\n",
    "        block_idx=3,\n",
    "        params={\n",
    "            \"input_fn_autotune\": False\n",
    "        },\n",
    "        training=False\n",
    "    )().take(1)\n",
    "\n",
    "    for batch in dataset:\n",
    "        features, label = batch\n",
    "        numpy_batch = {\n",
    "            k: image_utils.descale_images(v.numpy())\n",
    "            for k, v in features.items()\n",
    "        }\n",
    "elif dataset_name == \"cifar10_car\":\n",
    "    size = 32\n",
    "    dataset = inference_inputs.read_dataset(\n",
    "        file_pattern=\"data/cifar10_car/test_{0}x{0}_0.tfrecord\".format(size),\n",
    "        batch_size=batch_size_query_images,\n",
    "        block_idx=3,\n",
    "        params={\n",
    "            \"use_multiple_resolution_records\": False,\n",
    "            \"tf_record_example_schema\": [\n",
    "                {\n",
    "                    \"name\": \"image_raw\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"str\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"label\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                }\n",
    "            ],\n",
    "            \"image_feature_name\": \"image_raw\",\n",
    "            \"image_encoding\": \"raw\",\n",
    "            \"image_predownscaled_height\": 32,\n",
    "            \"image_predownscaled_width\": 32,\n",
    "            \"image_depth\": 3,\n",
    "            \"label_feature_name\": \"label\",\n",
    "            \"input_fn_autotune\": False,\n",
    "            \"generator_projection_dims\": [4, 4, 512]\n",
    "        }\n",
    "    )().take(1)\n",
    "\n",
    "    for batch in dataset:\n",
    "        features, label = batch\n",
    "        numpy_batch = {k: v.numpy() for k, v in features.items()}\n",
    "elif dataset_name == \"cifar10\":\n",
    "    size = 32\n",
    "    dataset = inference_inputs.read_dataset(\n",
    "        file_pattern=\"gs://.../data/cifar10/test_{0}x{0}_0.tfrecord\".format(\n",
    "            size\n",
    "        ),\n",
    "        batch_size=batch_size_query_images,\n",
    "        block_idx=3,\n",
    "        params={\n",
    "            \"use_multiple_resolution_records\": False,\n",
    "            \"tf_record_example_schema\": [\n",
    "                {\n",
    "                    \"name\": \"image_raw\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"str\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"label\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"int\"\n",
    "                }\n",
    "            ],\n",
    "            \"image_feature_name\": \"image_raw\",\n",
    "            \"image_encoding\": \"raw\",\n",
    "            \"image_predownscaled_height\": 32,\n",
    "            \"image_predownscaled_width\": 32,\n",
    "            \"image_depth\": 3,\n",
    "            \"label_feature_name\": \"label\",\n",
    "            \"input_fn_autotune\": False,\n",
    "            \"generator_projection_dims\": [4, 4, 512]\n",
    "        }\n",
    "    )().take(1)\n",
    "\n",
    "    for batch in dataset:\n",
    "        features, label = batch\n",
    "        numpy_batch = {k: v.numpy() for k, v in features.items()}\n",
    "elif dataset_name == \"celeba_hq\":\n",
    "    size = 1024\n",
    "    dataset = inference_inputs.read_dataset(\n",
    "        file_pattern=\"gs://.../data/celeba_hq/train-00000-of-00080\",\n",
    "        batch_size=batch_size_query_images,\n",
    "        block_idx=8,\n",
    "        params={\n",
    "            \"use_multiple_resolution_records\": False,\n",
    "            \"tf_record_example_schema\": [\n",
    "                {\n",
    "                    \"name\": \"image_raw\",\n",
    "                    \"type\": \"FixedLen\",\n",
    "                    \"shape\": [],\n",
    "                    \"dtype\": \"str\"\n",
    "                }\n",
    "            ],\n",
    "            \"image_feature_name\": \"image_raw\",\n",
    "            \"image_encoding\": \"jpeg\",\n",
    "            \"image_predownscaled_height\": 1024,\n",
    "            \"image_predownscaled_width\": 1024,\n",
    "            \"image_depth\": 3,\n",
    "            \"label_feature_name\": \"\",\n",
    "            \"input_fn_autotune\": False,\n",
    "            \"generator_projection_dims\": [4, 4, 512]\n",
    "        }\n",
    "    )().take(1)\n",
    "\n",
    "    for batch in dataset:\n",
    "        features = batch\n",
    "        numpy_batch = {k: v.numpy() for k, v in features.items()}\n",
    "\n",
    "query_images = numpy_batch[\"image\"]\n",
    "\n",
    "print(query_images.shape)\n",
    "image_utils.plot_images(images=query_images, depth=3, num_rows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6unS8M3I0xg"
   },
   "source": [
    "### Plot exports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_growth = gan_inference.plot_all_exports_by_architecture(\n",
    "    Z=Z,\n",
    "    query_images=query_images,\n",
    "    exports_on_gcs=True,\n",
    "    export_start_idx=0,\n",
    "    export_end_idx=17,\n",
    "    max_size=1024,\n",
    "    only_output_growth_set={i for i in range(9)},\n",
    "    num_rows=1,\n",
    "    generator_architecture=\"berg\",\n",
    "    overrides={\n",
    "        \"output_dir\": \"gs://.../trained_models/experiment\",\n",
    "\n",
    "        \"export_all_growth_phases\": False,\n",
    "\n",
    "        \"output_generated_images\": True,\n",
    "        \"output_encoded_generated_images\": True,\n",
    "\n",
    "        \"output_query_images\": True,\n",
    "\n",
    "        \"output_query_encoded_images\": True,\n",
    "\n",
    "        \"output_query_anomaly_images_sigmoid\": True,\n",
    "        \"output_query_anomaly_images_linear\": True,\n",
    "\n",
    "        \"output_query_mahalanobis_distances\": True,\n",
    "        \"output_query_mahalanobis_distance_images_sigmoid\": True,\n",
    "        \"output_query_mahalanobis_distance_images_linear\": True,\n",
    "\n",
    "        \"output_query_pixel_anomaly_flags\": True,\n",
    "\n",
    "        \"output_query_anomaly_scores\": False,\n",
    "        \"output_query_anomaly_flags\": False\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_by_growth = gan_inference.plot_all_exports_by_architecture(\n",
    "    Z=None,\n",
    "    query_images=query_images,\n",
    "    exports_on_gcs=False,\n",
    "    export_start_idx=0,\n",
    "    export_end_idx=17,\n",
    "    max_size=1024,\n",
    "    only_output_growth_set={i for i in range(9)},\n",
    "    num_rows=1,\n",
    "    generator_architecture=\"GANomaly\",\n",
    "    overrides={\n",
    "        \"output_dir\": \"gs://.../trained_models/experiment\",\n",
    "\n",
    "        \"export_all_growth_phases\": False,\n",
    "\n",
    "        \"output_query_images\": True,\n",
    "\n",
    "        \"output_query_gen_encoded_images\": True,\n",
    "        \"output_query_enc_encoded_images\": True,\n",
    "\n",
    "        \"output_query_anomaly_images_sigmoid\": True,\n",
    "        \"output_query_anomaly_images_linear\": True,\n",
    "\n",
    "        \"output_query_mahalanobis_distances\": True,\n",
    "        \"output_query_mahalanobis_distance_images_sigmoid\": True,\n",
    "        \"output_query_mahalanobis_distance_images_linear\": True,\n",
    "\n",
    "        \"output_query_pixel_anomaly_flags\": True,\n",
    "\n",
    "        \"output_query_anomaly_scores\": False,\n",
    "        \"output_query_anomaly_flags\": False\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0WOfCOLuI0v5",
    "XlYsY-iYI0v9",
    "547YZ57pI0wH",
    "5amZD9R-I0wR",
    "4XOSoRQdI0wU",
    "pAwYlzUcI0wW",
    "gCq9BjhWI0wa",
    "ZFR0jrEBI0wd",
    "-3FT7oPeI0wh",
    "8RAnzQn1I0wk",
    "plRFnmDzI0wo",
    "qTPKj0CtI0wr",
    "V4AwQzK8I0xT",
    "mxch4X7NI0xV"
   ],
   "name": "tf2_progranomaly_local.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
